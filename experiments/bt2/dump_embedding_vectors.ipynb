{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86614537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/darshan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad63ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path:../../local_models/bert-base-uncased_option1_with_bertram_bt2\n"
     ]
    }
   ],
   "source": [
    "local_model_base_dir = '../../local_models/'\n",
    "# Location of the model with single-tokens\n",
    "model_name = 'bert-base-uncased_option1_with_bertram_bt2'\n",
    "model_checkpoint_dir = local_model_base_dir + model_name\n",
    "print(f'Model path:{model_checkpoint_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f50f3208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PIE_list': ['IDmybadID', 'IDgameonID', 'IDchaseyourtailID', 'IDstealtheshowID', 'IDfromscratchID', 'IDlendahandID', 'IDatseaID', 'IDbiteyourlipID', 'IDdaylightrobberyID', 'IDactofgodID', 'IDbreaktheiceID', 'IDrunamileID', 'IDunderthetableID', 'IDholdyourtongueID', 'IDputthekiboshonID', 'IDindutchID', 'IDinthedriversseatID'], 'paraphrases': ['contest', 'ready for something', 'rush around ineffectually', 'very busy', 'center of attention', 'outshine', 'from very beginning', 'assist', 'help', 'confused', 'puzzled', 'repress an emotion', 'unfair trade', 'victim', 'severe natural event', 'relieve tension', 'start a conversation', 'reluctant', 'extremely unwilling', 'secretly or covertly', 'very drunk', 'remain silent', 'put an end to', 'check', 'curb', 'stop', 'in trouble', 'in disfavor', 'be in control', \"in the driver's seat\", 'make the decisions'], 'words': []}\n"
     ]
    }
   ],
   "source": [
    "wordlist_set_NAME = 'set1'\n",
    "wordlist_set_json_file = '../../data/emb_visuals/wordlist_set1.json'\n",
    "\n",
    "# The common set of tokens, paraphrases and words to be considered in the final output\n",
    "with open(wordlist_set_json_file, 'r') as jfile:\n",
    "    WORDLIST_DICT = json.load(jfile)\n",
    "print(WORDLIST_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049b9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment name\n",
    "exp_name = 'bt2'\n",
    "\n",
    "IS_BERTRAM_FORMAT = True\n",
    "\n",
    "token_PIE_mapping_file = '../../data/token_files/option1_idioms.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c970d93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should BERTRAM format be used: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Should BERTRAM format be used: {IS_BERTRAM_FORMAT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "906d7f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "dump_dir = './embedding_dump/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacadfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e4bf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to BERTRAM format!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idiom</th>\n",
       "      <th>idiom_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>act of God</td>\n",
       "      <td>&lt;BERTRAM:IDactofgodID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>from scratch</td>\n",
       "      <td>&lt;BERTRAM:IDfromscratchID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>chase your tail</td>\n",
       "      <td>&lt;BERTRAM:IDchaseyourtailID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>under the table</td>\n",
       "      <td>&lt;BERTRAM:IDunderthetableID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>at sea</td>\n",
       "      <td>&lt;BERTRAM:IDatseaID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>game on</td>\n",
       "      <td>&lt;BERTRAM:IDgameonID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>run a mile</td>\n",
       "      <td>&lt;BERTRAM:IDrunamileID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>break the ice</td>\n",
       "      <td>&lt;BERTRAM:IDbreaktheiceID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>in Dutch</td>\n",
       "      <td>&lt;BERTRAM:IDindutchID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>lend a hand</td>\n",
       "      <td>&lt;BERTRAM:IDlendahandID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>my bad</td>\n",
       "      <td>&lt;BERTRAM:IDmybadID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>hold your tongue</td>\n",
       "      <td>&lt;BERTRAM:IDholdyourtongueID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>daylight robbery</td>\n",
       "      <td>&lt;BERTRAM:IDdaylightrobberyID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>steal the show</td>\n",
       "      <td>&lt;BERTRAM:IDstealtheshowID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>in the driver's seat</td>\n",
       "      <td>&lt;BERTRAM:IDinthedriversseatID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>bite your lip</td>\n",
       "      <td>&lt;BERTRAM:IDbiteyourlipID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>put the kibosh on</td>\n",
       "      <td>&lt;BERTRAM:IDputthekiboshonID&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     idiom                     idiom_token\n",
       "33              act of God          <BERTRAM:IDactofgodID>\n",
       "111           from scratch       <BERTRAM:IDfromscratchID>\n",
       "114        chase your tail     <BERTRAM:IDchaseyourtailID>\n",
       "131        under the table     <BERTRAM:IDunderthetableID>\n",
       "153                 at sea             <BERTRAM:IDatseaID>\n",
       "179                game on            <BERTRAM:IDgameonID>\n",
       "362             run a mile          <BERTRAM:IDrunamileID>\n",
       "500          break the ice       <BERTRAM:IDbreaktheiceID>\n",
       "674               in Dutch           <BERTRAM:IDindutchID>\n",
       "713            lend a hand         <BERTRAM:IDlendahandID>\n",
       "813                 my bad             <BERTRAM:IDmybadID>\n",
       "869       hold your tongue    <BERTRAM:IDholdyourtongueID>\n",
       "870       daylight robbery   <BERTRAM:IDdaylightrobberyID>\n",
       "1051        steal the show      <BERTRAM:IDstealtheshowID>\n",
       "1093  in the driver's seat  <BERTRAM:IDinthedriversseatID>\n",
       "1251         bite your lip       <BERTRAM:IDbiteyourlipID>\n",
       "1373     put the kibosh on    <BERTRAM:IDputthekiboshonID>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the PIEs and token strings\n",
    "df_pie_token_mapping = pd.read_csv(token_PIE_mapping_file)\n",
    "\n",
    "# Consider only those PIEs that present in the WORDLIST_DICT\n",
    "df_pie_token_mapping = df_pie_token_mapping[df_pie_token_mapping['idiom_token'].isin(WORDLIST_DICT['PIE_list'])]\n",
    "\n",
    "ID_BERTRAM_map = None\n",
    "if IS_BERTRAM_FORMAT:\n",
    "    # Convert the tokens to <BERTRAM:...> format\n",
    "    df_pie_token_mapping['idiom_token'] = df_pie_token_mapping['idiom_token'].map(lambda t: f\"<BERTRAM:{t}>\")\n",
    "    # For future use\n",
    "    ID_BERTRAM_map = {f\"<BERTRAM:{pie}>\" : pie for pie in WORDLIST_DICT['PIE_list']}\n",
    "    WORDLIST_DICT['PIE_list'] = [key for key,val in ID_BERTRAM_map.items()]\n",
    "\n",
    "    print('Converted to BERTRAM format!')\n",
    "\n",
    "display(df_pie_token_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f01720",
   "metadata": {},
   "source": [
    "## Consider the words in the MAGPIE corpus\n",
    "\n",
    "**Consider only those sentences where the current list of PIEs are used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e448cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained 1540 words from MAGPIE corpus\n"
     ]
    }
   ],
   "source": [
    "en_stopwords = stopwords.words('english')\n",
    "punc_remo_trans = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "en_stopwords.extend(WORDLIST_DICT['PIE_list'])\n",
    "en_stopwords = {s.lower() for s in en_stopwords}\n",
    "\n",
    "# Load the magpie training set\n",
    "MAGPIE_FULL_FILE = './tmp/magpie_full_exp3A_1.csv'\n",
    "df_magpie = pd.read_csv(MAGPIE_FULL_FILE)\n",
    "sent_list = df_magpie['sentence_0'].values\n",
    "\n",
    "MIN_COUNT = 1\n",
    "MAX_COUNT = 15\n",
    "MAGPIE_WORD_SET = set()\n",
    "# Add all the unique, non-stop words to a list (exclude the single tokens as well)\n",
    "word_counter = defaultdict(int)\n",
    "for sent in sent_list:\n",
    "    # Consider only those sentences that have the current list of PIEs\n",
    "    found=False\n",
    "    for pie in WORDLIST_DICT['PIE_list']:\n",
    "        if pie in sent:\n",
    "            found=True\n",
    "            break\n",
    "    if found:\n",
    "        sent = sent.translate(punc_remo_trans)\n",
    "        words = [word for word in sent.lower().split() if word not in en_stopwords]\n",
    "        words = [word for word in words if word.isalpha() and len(word)>2 and len(word)<=12]\n",
    "        # Count the word occurences\n",
    "        for word in words:\n",
    "            word_counter[word] += 1\n",
    "\n",
    "# Filter out very frequent and very rare words\n",
    "final_words = [word for word,count in word_counter.items() if count > MIN_COUNT and count < MAX_COUNT]\n",
    "MAGPIE_WORD_SET = set(final_words)\n",
    "\n",
    "print(f\"Obtained {len(MAGPIE_WORD_SET)} words from MAGPIE corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fb6d525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1540"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(sorted(word_counter.items(), key=lambda p: p[1]))\n",
    "len(MAGPIE_WORD_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d135b870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'demand', 'similar', 'indeed', 'literary', 'according', 'win', 'tells', 'windmills', 'modern', 'shall', 'entire', 'sides', 'prime', 'feet', 'italy', 'pressures', 'story', 'blank', 'exclusive', 'gather', 'required', 'must', 'things', 'caused', 'sentences', 'government', 'design', 'try', 'ways', 'bernard', 'unnecessary', 'opportunity', 'cups', 'absence', 'edward', 'example', 'flowering', 'matches', 'running', 'wheel', 'dumped', 'special', 'zoffany', 'procedure', 'agreement', 'royal', 'credit', 'ups', 'perfect', 'movement', 'particular', 'highlights', 'school', 'error', 'film', 'join', 'spoke', 'companies', 'hills', 'simple', 'fleet', 'occasion', 'want', 'handed', 'launched', 'install', 'force', 'engine', 'learned', 'dog', 'exercise', 'equipment', 'outfit', 'odeon', 'richmond', 'mean', 'american', 'staying', 'britain', 'traffic', 'assembly', 'clash', 'strength', 'right', 'room', 'supply', 'army', 'born', 'reach', 'seeking', 'writing', 'remains', 'viable', 'equivalent', 'joining', 'answer', 'enabling', 'pitches', 'nobody', 'production', 'younger', 'size', 'coronet', 'maker', 'peter', 'newton', 'organization', 'stuck', 'whale', 'fault', 'transvaal', 'sale', 'personal', 'tonight', 'throughout', 'boy', 'israel', 'authority', 'estimate', 'decided', 'warm', 'beat', 'blue', 'develop', 'working', 'wildlife', 'train', 'staff', 'helped', 'boat', 'formed', 'swindon', 'broken', 'almost', 'drive', 'mostly', 'introduced', 'lightning', 'james', 'state', 'rival', 'feels', 'spurs', 'fifteen', 'known', 'falling', 'went', 'able', 'far', 'border', 'large', 'however', 'association', 'stove', 'allowed', 'west', 'blockade', 'sounds', 'look', 'discovered', 'winds', 'confident', 'intelligence', 'buried', 'drinking', 'museums', 'shouted', 'complete', 'site', 'gon', 'boundaries', 'five', 'finish', 'slipped', 'coca', 'players', 'memory', 'expect', 'create', 'parents', 'pressure', 'putting', 'order', 'taught', 'profusion', 'bought', 'gave', 'national', 'roads', 'much', 'kicked', 'level', 'box', 'enemy', 'longer', 'tried', 'final', 'carrying', 'chosen', 'providing', 'sat', 'greater', 'wednesday', 'therefore', 'content', 'struggles', 'ball', 'lowering', 'coming', 'chairman', 'merchant', 'fwiday', 'sole', 'quickly', 'blossom', 'miss', 'technology', 'stop', 'attended', 'sharing', 'pulled', 'completely', 'forces', 'whatever', 'successful', 'endangered', 'hurworth', 'glass', 'need', 'thus', 'raiders', 'football', 'recordings', 'betty', 'class', 'launch', 'cover', 'visit', 'budget', 'internal', 'bob', 'wish', 'ones', 'morley', 'firstly', 'plays', 'lot', 'institutions', 'ducked', 'beach', 'list', 'means', 'ask', 'hours', 'designed', 'belfast', 'city', 'garden', 'seen', 'bank', 'keeping', 'kept', 'germany', 'virtually', 'turned', 'consumed', 'telling', 'station', 'jones', 'stretching', 'french', 'tom', 'friend', 'defence', 'conversion', 'willing', 'among', 'current', 'children', 'tae', 'quite', 'rebuilt', 'england', 'looks', 'head', 'insurance', 'grand', 'shoes', 'interested', 'experience', 'find', 'business', 'knew', 'october', 'neil', 'jenny', 'van', 'strokes', 'phoned', 'due', 'hospital', 'something', 'band', 'sorting', 'couple', 'damage', 'knows', 'dumping', 'corner', 'impossible', 'supported', 'services', 'fit', 'wigan', 'knowledge', 'opposition', 'designer', 'convinced', 'investment', 'german', 'tennis', 'expensive', 'night', 'throwbag', 'paid', 'advantage', 'chain', 'following', 'available', 'smith', 'windows', 'pressed', 'silver', 'provides', 'failed', 'alan', 'needed', 'unless', 'always', 'caught', 'possibly', 'profile', 'growth', 'basis', 'died', 'busy', 'became', 'flood', 'free', 'plot', 'corp', 'laid', 'reform', 'province', 'point', 'truly', 'parks', 'ensure', 'prevent', 'luxury', 'ordered', 'relieved', 'happen', 'easier', 'third', 'stand', 'wild', 'never', 'rugby', 'produced', 'killed', 'negligence', 'professional', 'natural', 'semi', 'information', 'nicholas', 'materials', 'university', 'needs', 'missed', 'seemed', 'world', 'tickets', 'luke', 'fall', 'bit', 'attending', 'sight', 'burst', 'haunted', 'biggest', 'lives', 'bohinen', 'captured', 'issue', 'excellent', 'generally', 'sand', 'course', 'eldest', 'college', 'practice', 'crews', 'trouble', 'county', 'attached', 'feel', 'physical', 'ever', 'leicester', 'leaders', 'john', 'flag', 'colchester', 'elderly', 'kansas', 'methods', 'factor', 'breeds', 'store', 'opened', 'ship', 'laptop', 'returns', 'chipped', 'expenditure', 'tomorrow', 'helping', 'appear', 'police', 'moment', 'corridor', 'health', 'growing', 'described', 'friendly', 'okay', 'yet', 'video', 'task', 'outside', 'hill', 'western', 'technical', 'ministry', 'brother', 'village', 'walk', 'increasingly', 'art', 'lexicons', 'mezzanine', 'european', 'lead', 'soccer', 'steering', 'construct', 'architect', 'evening', 'accepted', 'playing', 'process', 'robert', 'across', 'lamp', 'media', 'northern', 'let', 'eye', 'leading', 'yesterday', 'losing', 'earlier', 'customers', 'letters', 'reached', 'knees', 'characters', 'erm', 'york', 'thanks', 'meet', 'land', 'end', 'tide', 'bad', 'cut', 'fashion', 'women', 'swim', 'name', 'seven', 'theyve', 'remembered', 'storms', 'weekend', 'interest', 'manner', 'run', 'search', 'knots', 'ambitions', 'please', 'marine', 'recaptured', 'wanted', 'cheaper', 'taligent', 'schools', 'goes', 'secondly', 'present', 'trained', 'creating', 'portuguese', 'met', 'screens', 'bunny', 'carried', 'succession', 'half', 'law', 'rest', 'compared', 'clear', 'inter', 'fully', 'water', 'spain', 'programs', 'davis', 'president', 'bus', 'cricket', 'aim', 'passed', 'expected', 'choice', 'scored', 'allocate', 'gas', 'begin', 'impression', 'apparently', 'hand', 'breaks', 'likely', 'minister', 'post', 'ancient', 'rose', 'seat', 'somewhere', 'researchers', 'player', 'saved', 'oil', 'race', 'small', 'wore', 'uncertain', 'read', 'scale', 'ban', 'recorded', 'come', 'wind', 'hauls', 'bare', 'house', 'likes', 'winter', 'line', 'buildings', 'kicking', 'plaintiff', 'waste', 'plant', 'moves', 'started', 'good', 'performance', 'calls', 'stare', 'power', 'ideas', 'route', 'main', 'cooperation', 'floor', 'beyond', 'season', 'behind', 'loss', 'efficient', 'later', 'big', 'difficulty', 'stops', 'inc', 'area', 'landing', 'states', 'drowned', 'speak', 'low', 'latest', 'test', 'places', 'italian', 'sort', 'told', 'repository', 'monitoring', 'case', 'keep', 'pre', 'hear', 'attack', 'margin', 'nick', 'problems', 'control', 'jenkins', 'suppose', 'moved', 'subject', 'saving', 'conscious', 'rather', 'bed', 'prestigious', 'neck', 'vessels', 'voices', 'courts', 'report', 'history', 'contribute', 'received', 'finale', 'radioactive', 'local', 'plans', 'systems', 'kitchen', 'response', 'latter', 'membership', 'liberal', 'harvest', 'upon', 'languages', 'tell', 'points', 'derby', 'uncle', 'century', 'cent', 'management', 'front', 'gabriel', 'ice', 'played', 'areas', 'planned', 'editor', 'georgia', 'created', 'april', 'today', 'thought', 'despite', 'cup', 'industrial', 'heard', 'nothing', 'brave', 'initially', 'plate', 'officer', 'steps', 'wardrobe', 'rigs', 'lived', 'protection', 'department', 'fact', 'knee', 'clearly', 'came', 'gazing', 'red', 'culture', 'tracks', 'offering', 'opposed', 'successfully', 'students', 'trial', 'away', 'products', 'union', 'boys', 'record', 'bon', 'selling', 'scores', 'tyre', 'called', 'month', 'billiards', 'written', 'frame', 'east', 'general', 'file', 'build', 'appointment', 'heart', 'drawing', 'talk', 'eat', 'none', 'necessarily', 'bettie', 'saw', 'road', 'turn', 'meeting', 'star', 'shock', 'mention', 'colleagues', 'forms', 'games', 'chair', 'defences', 'view', 'happened', 'champion', 'foreign', 'displayed', 'effective', 'collection', 'lower', 'division', 'disk', 'chris', 'future', 'scotland', 'length', 'desire', 'reduced', 'energy', 'regulations', 'qualified', 'responsible', 'understood', 'cast', 'per', 'fight', 'shown', 'midfield', 'nature', 'option', 'capacity', 'taken', 'act', 'stockport', 'might', 'effect', 'less', 'runners', 'learning', 'villa', 'chapel', 'agricultural', 'suggested', 'firm', 'festival', 'turner', 'least', 'towards', 'date', 'important', 'works', 'street', 'press', 'junk', 'side', 'feeling', 'paul', 'development', 'problem', 'says', 'daughter', 'motto', 'central', 'though', 'usually', 'published', 'whilst', 'stock', 'crucial', 'going', 'users', 'compensation', 'thinking', 'informed', 'hope', 'think', 'tough', 'field', 'statutory', 'fourth', 'king', 'established', 'encouraged', 'connections', 'grounds', 'better', 'assume', 'safety', 'sit', 'scraps', 'convention', 'attempting', 'lancashire', 'memories', 'wooden', 'building', 'stay', 'home', 'sail', 'yeah', 'luck', 'wrist', 'religious', 'picked', 'coast', 'printed', 'ulster', 'pendulum', 'often', 'yes', 'supporting', 'direct', 'extra', 'competitors', 'shipping', 'week', 'father', 'crept', 'gossip', 'particularly', 'opponent', 'youngster', 'naval', 'eyes', 'attractive', 'jumps', 'follow', 'leaving', 'remove', 'cap', 'primary', 'firms', 'thousand', 'true', 'sizes', 'gallery', 'worked', 'asked', 'mill', 'experiences', 'fresh', 'probably', 'lear', 'monday', 'ships', 'explained', 'training', 'missile', 'speaking', 'pattern', 'scrapped', 'lady', 'sure', 'pity', 'soon', 'normally', 'rule', 'mrs', 'excuse', 'occur', 'restricted', 'racing', 'difference', 'square', 'felt', 'money', 'rescue', 'fans', 'television', 'expects', 'friday', 'knock', 'hour', 'johnny', 'crawled', 'bedroom', 'change', 'consequences', 'including', 'ago', 'perhaps', 'philosophy', 'park', 'lily', 'break', 'failure', 'show', 'safe', 'mighty', 'designated', 'looked', 'members', 'winger', 'yards', 'offer', 'theft', 'mad', 'officers', 'spread', 'names', 'developing', 'economic', 'challenge', 'team', 'stopping', 'jurisdiction', 'hit', 'spring', 'survival', 'regularly', 'words', 'compete', 'trying', 'anyone', 'sufficient', 'companion', 'missing', 'match', 'aspect', 'tyres', 'fought', 'poverty', 'hide', 'help', 'choose', 'four', 'jack', 'event', 'miles', 'system', 'involved', 'already', 'powers', 'causes', 'former', 'bar', 'zelda', 'brownies', 'bird', 'agreed', 'round', 'showing', 'radio', 'structure', 'british', 'market', 'fairly', 'friends', 'trapped', 'watch', 'winning', 'fell', 'computer', 'highly', 'collective', 'warren', 'straight', 'anything', 'painting', 'cash', 'dutch', 'scottish', 'men', 'goals', 'meant', 'suggest', 'gracious', 'software', 'seems', 'refused', 'disaster', 'actually', 'gone', 'result', 'hero', 'taking', 'shoe', 'either', 'operation', 'united', 'tuesday', 'sun', 'reply', 'others', 'hot', 'security', 'height', 'delighted', 'wood', 'fine', 'part', 'carry', 'set', 'shaun', 'fifty', 'spent', 'apprentices', 'leeds', 'miraculous', 'giving', 'young', 'next', 'battle', 'continue', 'fisherman', 'ride', 'within', 'sister', 'card', 'risk', 'series', 'readers', 'singing', 'rope', 'strange', 'seeing', 'remember', 'attempt', 'happy', 'arts', 'using', 'apart', 'amateur', 'saying', 'grabbing', 'charles', 'nearly', 'whose', 'pads', 'stars', 'husband', 'commercial', 'somebody', 'ill', 'sitting', 'saturdays', 'bid', 'ari', 'making', 'ahead', 'space', 'display', 'chest', 'rnli', 'various', 'single', 'doubt', 'previous', 'sound', 'score', 'live', 'plane', 'existing', 'enemies', 'receiving', 'london', 'entwined', 'provide', 'fun', 'bristol', 'price', 'investigate', 'inherited', 'dictionaries', 'found', 'shake', 'spanish', 'chat', 'object', 'efforts', 'manager', 'man', 'storm', 'fingers', 'driven', 'continuing', 'research', 'pitch', 'eight', 'battles', 'share', 'considered', 'nuclear', 'finally', 'sent', 'language', 'texas', 'foot', 'ruth', 'albania', 'league', 'action', 'seldom', 'license', 'learn', 'support', 'loan', 'sons', 'brought', 'obviously', 'goal', 'hms', 'morning', 'package', 'network', 'helps', 'entirely', 'environment', 'rocks', 'leo', 'popular', 'kudos', 'binding', 'vulcan', 'fellow', 'launching', 'fast', 'model', 'past', 'necessary', 'election', 'eton', 'policy', 'party', 'jason', 'prop', 'track', 'banned', 'cruise', 'hard', 'maritime', 'groups', 'dialects', 'air', 'cross', 'oclock', 'federal', 'bottom', 'group', 'done', 'variety', 'nevertheless', 'open', 'catches', 'collect', 'looking', 'days', 'finished', 'pepys', 'decision', 'rough', 'note', 'hands', 'wriggled', 'town', 'hundreds', 'trainer', 'times', 'full', 'visitors', 'collapse', 'serious', 'really', 'texts', 'touch', 'success', 'asking', 'voice', 'evil', 'facility', 'vehicles', 'publicity', 'instance', 'joint', 'ability', 'stood', 'study', 'took', 'curton', 'community', 'nations', 'starts', 'healthy', 'led', 'billy', 'elsewhere', 'wrote', 'guidelines', 'kick', 'earned', 'laugh', 'lost', 'lord', 'bbc', 'stage', 'initiative', 'sheila', 'wickets', 'face', 'eccentric', 'machine', 'category', 'leaned', 'poison', 'lifeboat', 'san', 'countries', 'different', 'overheads', 'medal', 'november', 'impressed', 'everything', 'ran', 'hundred', 'france', 'centre', 'near', 'comes', 'girl', 'limerick', 'strode', 'drug', 'especially', 'fear', 'shook', 'soviet', 'mainly', 'position', 'complex', 'along', 'kid', 'terry', 'sir', 'together', 'country', 'unix', 'court', 'june', 'hoping', 'major', 'understand', 'jackson', 'fish', 'harder', 'whole', 'prepared', 'common', 'dogs', 'save', 'snooker', 'offshore', 'quality', 'edwards', 'democrats', 'wight', 'boats', 'rabbits', 'cold', 'top', 'ground', 'sky', 'window', 'tested', 'based', 'fire', 'early', 'occupied', 'imagine', 'maurice', 'dinky', 'tea', 'enough', 'standing', 'living', 'quick', 'certain', 'applies', 'torn', 'operating', 'eastern', 'question', 'diana', 'kind', 'give', 'williams', 'august', 'installed', 'aviation', 'breast', 'trade', 'dawn', 'move', 'conditions', 'catch', 'tour', 'minutes', 'negotiations', 'huge', 'september', 'direction', 'close', 'deck', 'engineering', 'door', 'kingdom', 'fed', 'courses', 'cat', 'programme', 'human', 'bringing', 'stroke', 'practical', 'nearby', 'talking', 'deep', 'eventually', 'given', 'europe', 'distance', 'marks', 'tasks', 'blockbuster', 'months', 'significant', 'weeks', 'pulling', 'lines', 'legs', 'family', 'ibm', 'nightmares', 'changes', 'idea', 'behaviour', 'everyone', 'instead', 'original', 'person', 'channel', 'church', 'got', 'terms', 'education', 'release', 'duke', 'captain', 'headmaster', 'charlotte', 'stuff', 'attention', 'effort', 'experienced', 'leader', 'seem', 'planning', 'another', 'form', 'drink', 'certainly', 'island', 'retrieve', 'someone', 'afterwards', 'acquired', 'brown', 'getting', 'place', 'project', 'avoid', 'collision', 'covered', 'gloucester', 'death', 'megatape', 'immediately', 'thirty', 'allies', 'recycling', 'heavy', 'worse', 'hat', 'body', 'enjoy', 'began', 'museum', 'pilot', 'fence', 'cost', 'science', 'standard', 'continued', 'dead', 'partly', 'political', 'reliable', 'thing', 'whether', 'green', 'export', 'restaurant', 'six', 'settle', 'managers', 'basically', 'victory', 'committee', 'traditional', 'mother', 'unlucky', 'council', 'china', 'river', 'else', 'guide', 'congress', 'cope', 'book', 'sharpe', 'club', 'possible', 'job', 'suddenly', 'curled', 'office', 'publishing', 'eager', 'magazine', 'finding', 'property', 'vehicle', 'debate', 'rolled', 'wars', 'ultimately', 'faster', 'escape', 'north', 'write', 'white', 'january', 'food', 'play', 'number', 'served', 'latin', 'easy', 'eighty', 'pollution', 'allegedly', 'placed', 'moving', 'sea', 'black', 'ashore', 'becoming', 'shop', 'wall', 'say', 'volatile', 'robinson', 'return', 'riders', 'lay', 'considering', 'lunch', 'sense', 'structures', 'violent', 'maybe', 'camera', 'travelling', 'financial', 'goods', 'ear', 'peace', 'unbelievably', 'held', 'broad', 'middle', 'game', 'paragraph', 'several', 'age', 'son', 'exist', 'venter', 'ireland', 'company', 'pick', 'stayed', 'meanwhile', 'high', 'woman', 'crew', 'sixty', 'complicated', 'english', 'tries', 'ready', 'drunk', 'arrived'}\n"
     ]
    }
   ],
   "source": [
    "print(MAGPIE_WORD_SET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f0518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ca653da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory check\n",
    "if os.path.isdir(dump_dir):\n",
    "    raise Exception(f\"Output directory {dump_dir} already exists!\")\n",
    "else:\n",
    "    os.makedirs(dump_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d252deab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../local_models/bert-base-uncased_option1_with_bertram_bt2 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../../local_models/bert-base-uncased_option1_with_bertram_bt2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded both the LM Model & the Tokenizer models\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model & tokenizers\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_dir)\n",
    "# Download the Tokenizer model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_dir, use_fast=True, truncation=True)\n",
    "print(f\"Loaded both the LM Model & the Tokenizer models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f26d163f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31783, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embedding matrix\n",
    "embedding_weights = model.bert.embeddings.word_embeddings.weight\n",
    "embedding_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f804f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15f261f8",
   "metadata": {},
   "source": [
    "# Create tokens-id mapping for all the tokens\n",
    "We need to get the embeddings for all the tokens and the constituent words of the PIEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "964fd234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! <BERTRAM:IDactofgodID> not found!\n",
      "ERROR! <BERTRAM:IDchaseyourtailID> not found!\n",
      "ERROR! <BERTRAM:IDdaylightrobberyID> not found!\n",
      "ERROR! <BERTRAM:IDinthedriversseatID> not found!\n",
      "Got token ids for 17 PIE single tokens and 38 words\n"
     ]
    }
   ],
   "source": [
    "#To store PIE singel tokens\n",
    "single_token_to_id_mapping = {}\n",
    "# To store constituent words of a PIE\n",
    "word_to_ids = {}\n",
    "\n",
    "for i,(pie, token_str) in df_pie_token_mapping.iterrows():\n",
    "    # First, get the id-token mapping for 'token_str'\n",
    "    if IS_BERTRAM_FORMAT:\n",
    "        if token_str in tokenizer.vocab: \n",
    "            token_id = tokenizer.vocab[token_str]\n",
    "        else:\n",
    "            print(f'ERROR! {token_str} not found!')\n",
    "            token_id = tokenizer.unk_token_id\n",
    "    else:\n",
    "        token_id = tokenizer.vocab[token_str.lower()]\n",
    "    # Add to the dict\n",
    "    single_token_to_id_mapping[token_str] = token_id\n",
    "    \n",
    "    # Next, process the individual words in the pie, find their token ids\n",
    "    pie_words = [pword.strip() for pword in pie.split() if pword not in word_to_ids]\n",
    "    for pword in pie_words:\n",
    "        token_ids = tokenizer.encode(pword, add_special_tokens=False)\n",
    "        word_to_ids[pword] = token_ids\n",
    "        \n",
    "print(f\"Got token ids for {len(single_token_to_id_mapping)} PIE single tokens and {len(word_to_ids)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c97398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'financially': 13732,\n",
       " '氵': 1894,\n",
       " '##て': 30191,\n",
       " 'उ': 1313,\n",
       " 'commodore': 12957,\n",
       " 'fivb': 28423,\n",
       " '##古': 30315,\n",
       " 'decrease': 9885,\n",
       " '[unused404]': 409,\n",
       " '##atter': 20097,\n",
       " 'moors': 24812,\n",
       " '##gen': 6914,\n",
       " '##lis': 6856,\n",
       " '##back': 5963,\n",
       " 'malik': 14360,\n",
       " '宇': 1819,\n",
       " 'grunt': 20696,\n",
       " 'failures': 15428,\n",
       " 'stumbling': 19730,\n",
       " 'comparative': 12596,\n",
       " 'ರ': 1401,\n",
       " 'novgorod': 24338,\n",
       " 'uneven': 17837,\n",
       " '<BERTRAM:IDclosecallID>': 30695,\n",
       " '26': 2656,\n",
       " 'exhaustion': 15575,\n",
       " 'electrode': 28688,\n",
       " 'textures': 29343,\n",
       " 'penny': 10647,\n",
       " '<BERTRAM:IDwaytogoID>': 31727,\n",
       " '[unused829]': 834,\n",
       " 'bedford': 12003,\n",
       " 'cypriot': 18543,\n",
       " 'apron': 20376,\n",
       " 'bundle': 14012,\n",
       " 'streamed': 18498,\n",
       " 'docks': 15093,\n",
       " 'massif': 24875,\n",
       " 'losers': 23160,\n",
       " 'almond': 26011,\n",
       " '##ifier': 18095,\n",
       " 'market': 3006,\n",
       " 'comic': 5021,\n",
       " 'appleton': 26050,\n",
       " 'afghanistan': 7041,\n",
       " '##ᵗ': 30041,\n",
       " 'province': 2874,\n",
       " 'innocence': 12660,\n",
       " 'brush': 8248,\n",
       " '##sters': 15608,\n",
       " '##rigues': 22934,\n",
       " '##ophone': 25232,\n",
       " '##ged': 5999,\n",
       " 'madrid': 6921,\n",
       " 'dimly': 25361,\n",
       " '##proof': 18907,\n",
       " '94': 6365,\n",
       " 'gen': 8991,\n",
       " '##hman': 13890,\n",
       " '<BERTRAM:IDlikeclockworkID>': 31140,\n",
       " 'flick': 17312,\n",
       " 'cupboard': 25337,\n",
       " 'skopje': 29255,\n",
       " '##kowski': 15449,\n",
       " 'nod': 7293,\n",
       " 'christophe': 23978,\n",
       " 'remington': 25282,\n",
       " '##vel': 15985,\n",
       " 'umpire': 20887,\n",
       " 'toby': 11291,\n",
       " 'predictions': 20932,\n",
       " '##ytic': 21252,\n",
       " 'wah': 22894,\n",
       " 'waterloo': 13784,\n",
       " 'cordoba': 17986,\n",
       " '##landa': 24448,\n",
       " '##rup': 21531,\n",
       " 'へ': 1675,\n",
       " 'homer': 11525,\n",
       " 'formula': 5675,\n",
       " '##bis': 18477,\n",
       " 'lgbt': 12010,\n",
       " 'char': 25869,\n",
       " 'sites': 4573,\n",
       " '##kes': 9681,\n",
       " 'gt': 14181,\n",
       " 'directorate': 13634,\n",
       " 'frantic': 15762,\n",
       " 'venus': 11691,\n",
       " 'licenses': 15943,\n",
       " '##tad': 17713,\n",
       " 'ノ': 1717,\n",
       " 'flatly': 24295,\n",
       " 'lowlands': 26411,\n",
       " 'prelate': 26595,\n",
       " '##bt': 19279,\n",
       " 'taxonomic': 27691,\n",
       " 'treating': 12318,\n",
       " '<BERTRAM:IDpointthefingerID>': 31372,\n",
       " '##ywood': 26985,\n",
       " 'workplace': 16165,\n",
       " 'proton': 20843,\n",
       " 'ق': 1292,\n",
       " '<BERTRAM:IDbirdsofafeatherID>': 30608,\n",
       " '37': 4261,\n",
       " 'ordained': 9492,\n",
       " '##nb': 27698,\n",
       " '<BERTRAM:IDupthespoutID>': 31707,\n",
       " 'valentine': 10113,\n",
       " 'accent': 9669,\n",
       " 'solely': 9578,\n",
       " '##evic': 17726,\n",
       " 'belly': 7579,\n",
       " 'enhanced': 9412,\n",
       " 'zen': 16729,\n",
       " 'orb': 19607,\n",
       " 'wilfred': 26026,\n",
       " '##erated': 16848,\n",
       " '##=': 29630,\n",
       " 'ice': 3256,\n",
       " '2012': 2262,\n",
       " 'zheng': 20985,\n",
       " 'greek': 3306,\n",
       " 'keller': 16155,\n",
       " '##η': 24824,\n",
       " '<BERTRAM:IDgoitaloneID>': 30909,\n",
       " '##ulation': 9513,\n",
       " 'infrastructure': 6502,\n",
       " 'updated': 7172,\n",
       " 'auburn': 12704,\n",
       " 'exploitation': 14427,\n",
       " 'mansion': 7330,\n",
       " '[unused713]': 718,\n",
       " '##bh': 23706,\n",
       " '##ロ': 30261,\n",
       " 'eta': 27859,\n",
       " 'negative': 4997,\n",
       " 'kilometres': 3717,\n",
       " 'scientology': 23845,\n",
       " 'documentation': 12653,\n",
       " '[unused918]': 923,\n",
       " 'formations': 13197,\n",
       " 'announced': 2623,\n",
       " '##hor': 16368,\n",
       " 'fremont': 22550,\n",
       " 'punt': 18975,\n",
       " 'emir': 23434,\n",
       " '##berto': 21201,\n",
       " '##stor': 23809,\n",
       " '##ma': 2863,\n",
       " 'calm': 5475,\n",
       " 'sarcasm': 20954,\n",
       " 'programming': 4730,\n",
       " '[unused490]': 495,\n",
       " 'ashford': 26545,\n",
       " '##‑': 30049,\n",
       " 'ribs': 10335,\n",
       " '<BERTRAM:IDbythesametokenID>': 30663,\n",
       " '<BERTRAM:IDthrowyourhatintheringID>': 31635,\n",
       " 'paired': 12739,\n",
       " '##llar': 17305,\n",
       " '[unused865]': 870,\n",
       " 'survived': 5175,\n",
       " 'insists': 16818,\n",
       " 'kant': 26044,\n",
       " 'yearning': 29479,\n",
       " 'tended': 11121,\n",
       " 'suffer': 9015,\n",
       " '##encies': 15266,\n",
       " 'bobbed': 29579,\n",
       " 'wrath': 14532,\n",
       " 'barcelona': 7623,\n",
       " 'chargers': 18649,\n",
       " '##ckle': 19250,\n",
       " 'europe': 2885,\n",
       " 'frankfurt': 9780,\n",
       " 'tasha': 25448,\n",
       " 'hart': 7530,\n",
       " 'centenary': 17705,\n",
       " 'moreno': 17921,\n",
       " 'capitalist': 19640,\n",
       " '##eis': 17580,\n",
       " 'overhead': 8964,\n",
       " '##fle': 21031,\n",
       " 'burke': 9894,\n",
       " 'perfectly': 6669,\n",
       " 'inspecting': 29508,\n",
       " 'wounded': 5303,\n",
       " 'supposedly': 10743,\n",
       " 'blockade': 15823,\n",
       " 'adherence': 29235,\n",
       " 'bonuses': 29563,\n",
       " 'eduardo': 14846,\n",
       " 'tucker': 9802,\n",
       " 'sh': 14021,\n",
       " 'acheron': 21427,\n",
       " 'federally': 20892,\n",
       " 'canvas': 10683,\n",
       " 'wc': 15868,\n",
       " 'erotic': 14253,\n",
       " '##µ': 29659,\n",
       " 'gaston': 18572,\n",
       " '[unused906]': 911,\n",
       " '##enberg': 11029,\n",
       " 'sober': 17358,\n",
       " 'statutes': 18574,\n",
       " 'rigged': 25216,\n",
       " 'speculated': 15520,\n",
       " '##feit': 21156,\n",
       " '##₃': 11622,\n",
       " '##サ': 30231,\n",
       " '336': 27954,\n",
       " '井': 1754,\n",
       " 'pad': 11687,\n",
       " 'speaker': 5882,\n",
       " '##り': 30212,\n",
       " 'cassie': 8869,\n",
       " 'ufc': 11966,\n",
       " 'perennial': 14638,\n",
       " 'cookies': 16324,\n",
       " 'monsieur': 21380,\n",
       " 'corpus': 13931,\n",
       " '[unused70]': 71,\n",
       " 'fatally': 26292,\n",
       " 'aired': 4836,\n",
       " 'egyptians': 23437,\n",
       " '##ɛ': 29275,\n",
       " 'weigh': 17042,\n",
       " '1667': 27643,\n",
       " '##ի': 29772,\n",
       " '[unused956]': 961,\n",
       " 'completed': 2949,\n",
       " '##cit': 26243,\n",
       " '<BERTRAM:IDsmokeandmirrorsID>': 31533,\n",
       " 'brig': 16908,\n",
       " '##vating': 26477,\n",
       " 'countries': 3032,\n",
       " 'lively': 17133,\n",
       " 'tony': 4116,\n",
       " 'mojo': 28017,\n",
       " '[unused789]': 794,\n",
       " 'induction': 15946,\n",
       " '<BERTRAM:IDsweatlikeapigID>': 31571,\n",
       " 'middleweight': 18741,\n",
       " '™': 1580,\n",
       " 'optics': 21026,\n",
       " '##hil': 19466,\n",
       " '##lav': 14973,\n",
       " 'endings': 21306,\n",
       " 'modeling': 11643,\n",
       " 'garnered': 13056,\n",
       " '1a': 20720,\n",
       " '##el': 2884,\n",
       " 'expanse': 22944,\n",
       " '##we': 8545,\n",
       " 'ransom': 16540,\n",
       " '##bay': 15907,\n",
       " '##ч': 29752,\n",
       " 'erie': 13374,\n",
       " '[unused372]': 377,\n",
       " 'screenwriter': 11167,\n",
       " 'hurts': 13403,\n",
       " '##oted': 27428,\n",
       " '##pp': 9397,\n",
       " 'carr': 12385,\n",
       " '<BERTRAM:IDloseheartID>': 31157,\n",
       " 'sloane': 17558,\n",
       " 'hidalgo': 24715,\n",
       " 'artefacts': 25762,\n",
       " '##zzling': 20838,\n",
       " 'nsa': 23971,\n",
       " 'mcintyre': 24564,\n",
       " 'ion': 10163,\n",
       " '®': 1079,\n",
       " 'foreman': 18031,\n",
       " 'heaviest': 26858,\n",
       " 'veto': 22102,\n",
       " 'park': 2380,\n",
       " 'ua': 25423,\n",
       " 'spartans': 24293,\n",
       " '##ified': 7810,\n",
       " 'kepler': 28219,\n",
       " 'servants': 8858,\n",
       " 'clinton': 7207,\n",
       " '##power': 11452,\n",
       " '##zine': 21254,\n",
       " 'wal': 24547,\n",
       " 'this': 2023,\n",
       " '##lellan': 25839,\n",
       " 'hatfield': 26853,\n",
       " 'conflicts': 9755,\n",
       " 'chamberlain': 13904,\n",
       " '##rier': 16252,\n",
       " 'flawed': 25077,\n",
       " 'promote': 5326,\n",
       " '##iated': 15070,\n",
       " 'managed': 3266,\n",
       " 'oceans': 17401,\n",
       " 'स': 1338,\n",
       " 'exempt': 11819,\n",
       " 'air': 2250,\n",
       " 'chapter': 3127,\n",
       " '##wood': 3702,\n",
       " '##ise': 5562,\n",
       " 'catherine': 6615,\n",
       " 'factual': 25854,\n",
       " 'a2': 22441,\n",
       " 'strikers': 26049,\n",
       " '##oire': 26250,\n",
       " 'organisations': 8593,\n",
       " '##bling': 9709,\n",
       " 'riches': 26768,\n",
       " 'protestants': 19592,\n",
       " 'caller': 20587,\n",
       " '##dan': 7847,\n",
       " 'apocalyptic': 27660,\n",
       " 'carol': 8594,\n",
       " 'cardinal': 7185,\n",
       " 'demonstrated': 7645,\n",
       " 'melancholy': 22247,\n",
       " 'sir': 2909,\n",
       " 'dat': 23755,\n",
       " 'elvis': 12280,\n",
       " 'bunker': 15742,\n",
       " '##eil': 24359,\n",
       " 'ھ': 1307,\n",
       " 'crimea': 21516,\n",
       " 'alumnus': 19678,\n",
       " 'artery': 16749,\n",
       " 'breeze': 9478,\n",
       " 'piracy': 24386,\n",
       " 'hog': 27589,\n",
       " '原': 1787,\n",
       " 'て': 1665,\n",
       " 'signs': 5751,\n",
       " '##zing': 6774,\n",
       " 'affiliated': 6989,\n",
       " 'defender': 8291,\n",
       " 'aces': 20232,\n",
       " 'sara': 7354,\n",
       " 'purification': 28406,\n",
       " 'regretted': 18991,\n",
       " 'coe': 24873,\n",
       " '##rin': 6657,\n",
       " 'traversed': 27797,\n",
       " 'prepared': 4810,\n",
       " 'slayer': 20005,\n",
       " '##tute': 24518,\n",
       " 'communicate': 10639,\n",
       " 'shower': 6457,\n",
       " 'ß': 1096,\n",
       " '##text': 18209,\n",
       " 'stitch': 26035,\n",
       " 'novak': 19580,\n",
       " 'demonstrates': 16691,\n",
       " 'vehicles': 4683,\n",
       " 'schmidt': 12940,\n",
       " 'drilled': 24311,\n",
       " 'sought': 4912,\n",
       " '##owe': 29385,\n",
       " 'bumps': 18548,\n",
       " 'chiefly': 15897,\n",
       " 'rites': 17105,\n",
       " 'bertram': 27515,\n",
       " 'projective': 27473,\n",
       " 'flare': 17748,\n",
       " 'davies': 9082,\n",
       " 'zoning': 27462,\n",
       " 'assaulted': 17536,\n",
       " '<BERTRAM:IDontherunID>': 31294,\n",
       " 'lengthy': 12401,\n",
       " '<BERTRAM:IDrunthegauntletID>': 31466,\n",
       " '[unused950]': 955,\n",
       " 'キ': 1701,\n",
       " '48': 4466,\n",
       " 'substituted': 17316,\n",
       " 'kw': 6448,\n",
       " 'deadly': 9252,\n",
       " 'hamburger': 24575,\n",
       " '##ivision': 24607,\n",
       " '<BERTRAM:IDspititoutID>': 31543,\n",
       " '[unused66]': 67,\n",
       " '巿': 1837,\n",
       " 'postage': 22981,\n",
       " '##pipe': 24548,\n",
       " '##lein': 19856,\n",
       " 'holder': 9111,\n",
       " '##worm': 22769,\n",
       " 'magical': 8687,\n",
       " 'bacon': 11611,\n",
       " 'wisdom': 9866,\n",
       " 'qu': 24209,\n",
       " 'daughter': 2684,\n",
       " 'informed': 6727,\n",
       " 'amateur': 5515,\n",
       " '295': 21679,\n",
       " '##aging': 16594,\n",
       " 'swell': 18370,\n",
       " 'heritage': 4348,\n",
       " '##neck': 18278,\n",
       " '610': 19827,\n",
       " '##vation': 21596,\n",
       " '##nery': 27415,\n",
       " 'paler': 24489,\n",
       " 'tasks': 8518,\n",
       " 'cdp': 8561,\n",
       " 'symphonies': 29355,\n",
       " 'bandwidth': 20235,\n",
       " 'maison': 26420,\n",
       " '268': 25143,\n",
       " '##aya': 12186,\n",
       " '<BERTRAM:IDthickasthievesID>': 31623,\n",
       " '105': 8746,\n",
       " 'flesh': 5771,\n",
       " 'loyal': 8884,\n",
       " '[unused16]': 17,\n",
       " 'report': 3189,\n",
       " 'cd': 3729,\n",
       " 'ʾ': 1147,\n",
       " 'excluded': 12421,\n",
       " '##nti': 16778,\n",
       " '##geny': 17487,\n",
       " '##puram': 17809,\n",
       " 'demeanor': 21745,\n",
       " '98': 5818,\n",
       " '<BERTRAM:IDkeepalidonID>': 31082,\n",
       " '[unused847]': 852,\n",
       " 'gs': 28177,\n",
       " '##kshi': 27488,\n",
       " 'rower': 21984,\n",
       " '##gul': 24848,\n",
       " '##mage': 26860,\n",
       " '<BERTRAM:IDinthepinkID>': 31048,\n",
       " '##fest': 14081,\n",
       " 'naming': 10324,\n",
       " 'narration': 21283,\n",
       " 'resembled': 15881,\n",
       " '##kken': 24192,\n",
       " 'umar': 27981,\n",
       " 'unpleasant': 16010,\n",
       " 'teaches': 12011,\n",
       " 'agenda': 11376,\n",
       " 'isolation': 12477,\n",
       " '##आ': 29848,\n",
       " 'observer': 9718,\n",
       " 'aluminium': 14794,\n",
       " 'newcomers': 24159,\n",
       " 'milan': 6954,\n",
       " 'presided': 15506,\n",
       " 'land': 2455,\n",
       " '##owed': 15096,\n",
       " '##orne': 23846,\n",
       " '##$': 29615,\n",
       " '##enay': 27727,\n",
       " '##verted': 26686,\n",
       " 'torso': 15190,\n",
       " '<BERTRAM:IDatthedropofahatID>': 30567,\n",
       " 'ᵈ': 1498,\n",
       " '747': 25374,\n",
       " 'catastrophe': 25539,\n",
       " 'mitchell': 6395,\n",
       " 'flour': 13724,\n",
       " 'teeth': 4091,\n",
       " 'callie': 20072,\n",
       " 'gloves': 11875,\n",
       " 'ว': 1419,\n",
       " 'ა': 1438,\n",
       " 'truth': 3606,\n",
       " '##hering': 22658,\n",
       " '##xon': 22500,\n",
       " 'topical': 25665,\n",
       " 'postdoctoral': 29272,\n",
       " '##t': 2102,\n",
       " 'substitute': 7681,\n",
       " 'frogs': 17582,\n",
       " '##fk': 24316,\n",
       " 'quarterfinal': 29380,\n",
       " 'archers': 23118,\n",
       " 'cerebral': 18439,\n",
       " '##olf': 28027,\n",
       " 'ein': 16417,\n",
       " 'uta': 28981,\n",
       " 'wrapped': 5058,\n",
       " '##tting': 13027,\n",
       " '##cross': 16458,\n",
       " 'gleam': 24693,\n",
       " '##avio': 28471,\n",
       " '<BERTRAM:IDrideroughshodoverID>': 31434,\n",
       " 'concludes': 14730,\n",
       " '<BERTRAM:IDseparatethewheatfromthechaffID>': 31490,\n",
       " 'reconciled': 28348,\n",
       " 'brooks': 8379,\n",
       " 'weapons': 4255,\n",
       " 'scrutiny': 17423,\n",
       " 'strife': 27865,\n",
       " '[unused592]': 597,\n",
       " '[unused651]': 656,\n",
       " '<BERTRAM:IDtakeitfrommeID>': 31587,\n",
       " 'lola': 15137,\n",
       " 'reuben': 17294,\n",
       " '##nified': 25201,\n",
       " 'b': 1038,\n",
       " 'nostrils': 15325,\n",
       " 'bowled': 19831,\n",
       " 'tarzan': 24566,\n",
       " 'oct': 13323,\n",
       " 'dhaka': 16479,\n",
       " '##edance': 29605,\n",
       " 'warwick': 13283,\n",
       " 'assimilation': 27574,\n",
       " 'brightened': 28996,\n",
       " '1910s': 28088,\n",
       " '龍': 1982,\n",
       " 'mystic': 17477,\n",
       " '##aling': 21682,\n",
       " 'athletic': 5188,\n",
       " 'milne': 24377,\n",
       " '##point': 8400,\n",
       " '##jevic': 26782,\n",
       " 'ா': 1395,\n",
       " '##skin': 29334,\n",
       " 'gonna': 6069,\n",
       " '##ッ': 30237,\n",
       " '##ᵢ': 19109,\n",
       " 'cascade': 16690,\n",
       " '2500': 25108,\n",
       " 'repeatedly': 8385,\n",
       " 'aristocracy': 22706,\n",
       " 'erected': 7019,\n",
       " 'benny': 11945,\n",
       " 'eternal': 10721,\n",
       " '##yre': 16363,\n",
       " 'loki': 24143,\n",
       " 'gujarati': 26428,\n",
       " '<BERTRAM:IDtosaytheleastID>': 31654,\n",
       " 'agatha': 23863,\n",
       " 'christ': 4828,\n",
       " '##hol': 14854,\n",
       " '194': 19955,\n",
       " '##eem': 21564,\n",
       " 'rim': 11418,\n",
       " '##vn': 16022,\n",
       " '##sta': 9153,\n",
       " 'mexico': 3290,\n",
       " '##lco': 22499,\n",
       " '##dberg': 25190,\n",
       " 'imagination': 9647,\n",
       " 'budge': 24981,\n",
       " 'subsided': 26588,\n",
       " 'homemade': 25628,\n",
       " 'op': 6728,\n",
       " 'ndp': 21915,\n",
       " 'flutes': 28453,\n",
       " '274': 25586,\n",
       " 'banana': 15212,\n",
       " 'trunks': 20509,\n",
       " 'kyushu': 25885,\n",
       " '<BERTRAM:IDrubsomeoneupthewrongwayID>': 31455,\n",
       " '##a1': 27717,\n",
       " '[unused667]': 672,\n",
       " 'barge': 19398,\n",
       " 'chimed': 27460,\n",
       " 'concerned': 4986,\n",
       " 'sabotage': 20223,\n",
       " 'skirts': 18184,\n",
       " 'coptic': 27672,\n",
       " 'hardness': 23608,\n",
       " 'spoke': 3764,\n",
       " 'sheds': 25999,\n",
       " 'mirrors': 13536,\n",
       " 'orientation': 10296,\n",
       " '<BERTRAM:IDpushthepanicbuttonID>': 31400,\n",
       " 'upwards': 14873,\n",
       " 'rations': 29559,\n",
       " 'widespread': 6923,\n",
       " 'employees': 5126,\n",
       " 'similarity': 14402,\n",
       " '##child': 19339,\n",
       " 'contexts': 18046,\n",
       " 'confesses': 22826,\n",
       " 'fog': 9666,\n",
       " '##lift': 18412,\n",
       " 'suspended': 6731,\n",
       " 'acc': 16222,\n",
       " 'obscene': 27744,\n",
       " '##nio': 27678,\n",
       " '阿': 1971,\n",
       " 'console': 10122,\n",
       " 'cater': 23488,\n",
       " 'dreamer': 24726,\n",
       " 'row': 5216,\n",
       " 'commuter': 14334,\n",
       " 'chick': 14556,\n",
       " 'ʷ': 1143,\n",
       " 'remember': 3342,\n",
       " 'metropolis': 18236,\n",
       " 'superintendent': 9133,\n",
       " 'researched': 18800,\n",
       " 'newmarket': 22489,\n",
       " 'luis': 6446,\n",
       " 'exchanged': 10573,\n",
       " '1749': 24704,\n",
       " 'alma': 11346,\n",
       " '##icz': 18682,\n",
       " 'ส': 1420,\n",
       " '##dier': 24612,\n",
       " 'psychiatric': 13691,\n",
       " 'pulpit': 23134,\n",
       " 'ை': 1399,\n",
       " 'maharashtra': 12434,\n",
       " '<BERTRAM:IDonafullstomachID>': 31246,\n",
       " 'bounced': 13605,\n",
       " 'sheffield': 8533,\n",
       " 'victoria': 3848,\n",
       " '##iad': 28665,\n",
       " 'broughton': 29187,\n",
       " 'risk': 3891,\n",
       " '1864': 6717,\n",
       " '##opa': 29477,\n",
       " '##logram': 24915,\n",
       " 'turning': 3810,\n",
       " 'instance': 6013,\n",
       " '##cic': 19053,\n",
       " 'baha': 13253,\n",
       " 'orders': 4449,\n",
       " 'spoiled': 19582,\n",
       " 'sexy': 7916,\n",
       " 'acted': 6051,\n",
       " 'chemist': 15535,\n",
       " 'satire': 18312,\n",
       " 'goethe': 23173,\n",
       " '·': 1087,\n",
       " 'invincible': 25018,\n",
       " 'jan': 5553,\n",
       " '1975': 3339,\n",
       " '##cellular': 16882,\n",
       " 'billie': 18210,\n",
       " 'monsoon': 19183,\n",
       " '##rr': 12171,\n",
       " '##久': 30274,\n",
       " '[unused344]': 349,\n",
       " 'destroyers': 13242,\n",
       " 'library': 3075,\n",
       " '##ials': 26340,\n",
       " 'quezon': 26564,\n",
       " '##usions': 22016,\n",
       " 'baseline': 26163,\n",
       " 'disco': 12532,\n",
       " 'salaries': 20566,\n",
       " 'disciplinary': 17972,\n",
       " '##kong': 25460,\n",
       " '[unused11]': 12,\n",
       " 'castile': 15656,\n",
       " 'freddy': 19343,\n",
       " 'cried': 6639,\n",
       " '##ctions': 22014,\n",
       " '谷': 1951,\n",
       " 'escapes': 12976,\n",
       " 'wire': 7318,\n",
       " 'bled': 23919,\n",
       " 'bodo': 28137,\n",
       " '##社': 30450,\n",
       " 'barefoot': 22985,\n",
       " 'simulation': 12504,\n",
       " 'constructed': 3833,\n",
       " 'augsburg': 24362,\n",
       " 'heels': 8265,\n",
       " 'ვ': 1443,\n",
       " '1794': 13199,\n",
       " 'vowed': 18152,\n",
       " 'slide': 7358,\n",
       " 'gentle': 7132,\n",
       " 'cabbage': 28540,\n",
       " 'ip': 12997,\n",
       " '##inations': 22045,\n",
       " '##gged': 15567,\n",
       " '##git': 23806,\n",
       " 'non': 2512,\n",
       " 'eighteenth': 12965,\n",
       " 'tau': 19982,\n",
       " 'vengeance': 14096,\n",
       " '281': 22955,\n",
       " 'treatments': 13441,\n",
       " 'brand': 4435,\n",
       " 'roderick': 28326,\n",
       " 'heiress': 20020,\n",
       " 'elimination': 9614,\n",
       " '##aa': 11057,\n",
       " 'adults': 6001,\n",
       " '<BERTRAM:IDbynostretchoftheimaginationID>': 30662,\n",
       " 'internment': 29041,\n",
       " 'goats': 17977,\n",
       " 'boar': 24187,\n",
       " 'mode': 5549,\n",
       " 'confessed': 14312,\n",
       " '##vard': 25911,\n",
       " 'genres': 11541,\n",
       " 'dominique': 18165,\n",
       " '«': 1077,\n",
       " '##mond': 11442,\n",
       " 'submarines': 12622,\n",
       " '##date': 13701,\n",
       " 'resort': 7001,\n",
       " '##tt': 4779,\n",
       " '[unused234]': 239,\n",
       " 'debris': 11385,\n",
       " 'smartphone': 26381,\n",
       " '##wled': 28365,\n",
       " 'touchdown': 7921,\n",
       " 'cricket': 4533,\n",
       " 'colonies': 8355,\n",
       " '世': 1745,\n",
       " '##tree': 13334,\n",
       " 'surfing': 19967,\n",
       " 'ethnicity': 18240,\n",
       " 'slavic': 13838,\n",
       " 'lauderdale': 23520,\n",
       " '##rvis': 29074,\n",
       " 'stabilize': 27790,\n",
       " 'theme': 4323,\n",
       " 'initials': 20381,\n",
       " 'recorded': 2680,\n",
       " 'wing': 3358,\n",
       " 'sin': 8254,\n",
       " 'justify': 16114,\n",
       " 'contempt': 17152,\n",
       " 'overheard': 20443,\n",
       " '[unused852]': 857,\n",
       " '##egorical': 27203,\n",
       " '##ম': 29906,\n",
       " '<BERTRAM:IDflyakiteID>': 30833,\n",
       " 'addison': 18403,\n",
       " 'pouch': 21445,\n",
       " '##vable': 12423,\n",
       " 'combines': 13585,\n",
       " 'gazing': 16448,\n",
       " 'advantages': 12637,\n",
       " 'write': 4339,\n",
       " 'ellie': 10707,\n",
       " 'host': 3677,\n",
       " 'carmichael': 23537,\n",
       " '##drick': 24092,\n",
       " 'babe': 11561,\n",
       " 'drag': 8011,\n",
       " 'naga': 26539,\n",
       " 'nodes': 14164,\n",
       " 'borders': 6645,\n",
       " 'towns': 4865,\n",
       " 'tears': 4000,\n",
       " 'paige': 17031,\n",
       " 'lasts': 16180,\n",
       " 'engined': 21235,\n",
       " 'escaping': 13002,\n",
       " '##orous': 25373,\n",
       " '##স': 29912,\n",
       " 'reducing': 8161,\n",
       " 'russo': 17023,\n",
       " 'appoint': 16823,\n",
       " 'liking': 16663,\n",
       " 'trusting': 19836,\n",
       " 'worries': 15508,\n",
       " 'instructors': 19922,\n",
       " 'whaling': 23687,\n",
       " '##etano': 28752,\n",
       " '[unused545]': 550,\n",
       " 'ъ': 1205,\n",
       " '##fighter': 20027,\n",
       " '1774': 17593,\n",
       " 'galway': 14370,\n",
       " 'risks': 10831,\n",
       " 'de': 2139,\n",
       " 'dade': 27647,\n",
       " 'likened': 28834,\n",
       " 'ر': 1280,\n",
       " 'maharaja': 21609,\n",
       " 'ץ': 1262,\n",
       " '<BERTRAM:IDhavekittensID>': 30965,\n",
       " 'stalin': 13125,\n",
       " '##missible': 26770,\n",
       " '##gative': 26792,\n",
       " '##thic': 23048,\n",
       " 'cambridge': 4729,\n",
       " 'manipulate': 17708,\n",
       " 'jagged': 18187,\n",
       " 'ritchie': 20404,\n",
       " 'presbyterian': 10133,\n",
       " 'jamaican': 17851,\n",
       " '[unused394]': 399,\n",
       " 'residency': 14079,\n",
       " 'branched': 21648,\n",
       " 'societies': 8384,\n",
       " 'botanic': 27761,\n",
       " '##osomal': 27642,\n",
       " 'emilia': 20417,\n",
       " 'ulysses': 22784,\n",
       " 'bladder': 24176,\n",
       " '##lices': 29146,\n",
       " 'stem': 7872,\n",
       " 'delight': 12208,\n",
       " '##kei': 29501,\n",
       " '<BERTRAM:IDbetterthedevilyouknowID>': 30602,\n",
       " 'survey': 5002,\n",
       " 'bodies': 4230,\n",
       " 'elf': 17163,\n",
       " '##yat': 26139,\n",
       " '<BERTRAM:IDdrawabeadonID>': 30782,\n",
       " '<BERTRAM:IDtakeheartID>': 31586,\n",
       " 'canterbury': 9976,\n",
       " 'gained': 4227,\n",
       " '[unused557]': 562,\n",
       " '[unused882]': 887,\n",
       " '##nton': 15104,\n",
       " 'frequent': 6976,\n",
       " '##gers': 15776,\n",
       " 'gould': 14913,\n",
       " 'poke': 26202,\n",
       " 'northeastern': 8763,\n",
       " '##us': 2271,\n",
       " 'blacks': 10823,\n",
       " 'steep': 9561,\n",
       " 'rushing': 8375,\n",
       " 'generator': 13103,\n",
       " 'pamphlets': 24752,\n",
       " 'iso': 11163,\n",
       " '<BERTRAM:IDunderlockandkeyID>': 31685,\n",
       " 'conversion': 7584,\n",
       " 'declares': 18806,\n",
       " '##essed': 23656,\n",
       " 'underlying': 10318,\n",
       " 'emmy': 10096,\n",
       " '##dion': 29573,\n",
       " 'plead': 25803,\n",
       " 'γ': 1157,\n",
       " 'interact': 11835,\n",
       " '##anian': 26032,\n",
       " 'paolo': 14174,\n",
       " 'david': 2585,\n",
       " 'remotely': 19512,\n",
       " '##ych': 17994,\n",
       " 'trumpets': 26506,\n",
       " '##kat': 24498,\n",
       " 'delaying': 29391,\n",
       " 'abstract': 10061,\n",
       " 'isbn': 3175,\n",
       " 'м': 1191,\n",
       " '[unused505]': 510,\n",
       " 'ホ': 1722,\n",
       " '##lc': 15472,\n",
       " '士': 1807,\n",
       " 'incorrectly': 19721,\n",
       " 'inexpensive': 23766,\n",
       " '<BERTRAM:IDquickasaflashID>': 31417,\n",
       " 'kicked': 6476,\n",
       " 'prasad': 17476,\n",
       " 'ordeal': 23304,\n",
       " '##oric': 29180,\n",
       " 'missions': 6416,\n",
       " 'deeds': 15616,\n",
       " 'rafael': 10999,\n",
       " 'cellar': 15423,\n",
       " 'roasted': 28115,\n",
       " 'effective': 4621,\n",
       " 'par': 11968,\n",
       " 'scaled': 18953,\n",
       " '##bola': 24290,\n",
       " 'rubber': 8903,\n",
       " '##pur': 5311,\n",
       " 'stud': 16054,\n",
       " '##jure': 25243,\n",
       " 'kit': 8934,\n",
       " '##ল': 29909,\n",
       " '##gt': 13512,\n",
       " '##vern': 23062,\n",
       " 'moderately': 17844,\n",
       " 'asphalt': 16295,\n",
       " 'lou': 10223,\n",
       " 'pornography': 19378,\n",
       " 'covenant': 16077,\n",
       " 'policeman': 14460,\n",
       " '##ml': 19968,\n",
       " 'armand': 20371,\n",
       " 'ನ': 1400,\n",
       " 'playhouse': 17408,\n",
       " 'negotiated': 13630,\n",
       " 'pouring': 13053,\n",
       " 'windows': 3645,\n",
       " '650': 13757,\n",
       " 'upstream': 13909,\n",
       " 'lana': 16554,\n",
       " 'esq': 25325,\n",
       " 'women': 2308,\n",
       " 'beers': 18007,\n",
       " '##უ': 29990,\n",
       " 'subdistrict': 24150,\n",
       " '##wat': 24281,\n",
       " 'lac': 18749,\n",
       " 'aeronautics': 27459,\n",
       " 'arrested': 4727,\n",
       " 'h₂o': 24833,\n",
       " 'directions': 7826,\n",
       " 'arrow': 8612,\n",
       " 'antioch': 19078,\n",
       " 'adjustable': 26404,\n",
       " '<BERTRAM:IDuptheanteID>': 31705,\n",
       " '<BERTRAM:IDwetbehindtheearsID>': 31730,\n",
       " '1773': 19916,\n",
       " 'taunting': 29442,\n",
       " 'consultative': 28581,\n",
       " 'cardiff': 10149,\n",
       " 'defences': 16828,\n",
       " '##¨': 29651,\n",
       " 'neat': 15708,\n",
       " '##hett': 28499,\n",
       " 'regained': 11842,\n",
       " 'ian': 4775,\n",
       " 'antenna': 13438,\n",
       " 'battista': 28422,\n",
       " 'ₗ': 1566,\n",
       " 'financing': 12135,\n",
       " '[unused993]': 998,\n",
       " 'ł': 1105,\n",
       " 'tailor': 22701,\n",
       " 'miscellaneous': 25408,\n",
       " 'taste': 5510,\n",
       " 'tabloid': 24173,\n",
       " '##gar': 6843,\n",
       " '⇒': 1591,\n",
       " 'born': 2141,\n",
       " 'yes': 2748,\n",
       " 'garments': 21902,\n",
       " 'ே': 1398,\n",
       " 'materials': 4475,\n",
       " 'these': 2122,\n",
       " 'plaintiff': 20579,\n",
       " '<BERTRAM:IDlikeabearwithasoreheadID>': 31139,\n",
       " 'lateral': 11457,\n",
       " '##sd': 16150,\n",
       " '<BERTRAM:IDkickassID>': 31097,\n",
       " 'continues': 4247,\n",
       " '##ٹ': 29838,\n",
       " 'eritrea': 26040,\n",
       " 'harder': 6211,\n",
       " 'discovers': 9418,\n",
       " '##anto': 21634,\n",
       " 'housemates': 28152,\n",
       " 'brant': 29182,\n",
       " 'crumpled': 19814,\n",
       " 'gliding': 20292,\n",
       " '875': 27658,\n",
       " '##ros': 7352,\n",
       " 'become': 2468,\n",
       " '##mpt': 27718,\n",
       " 'tyrant': 26508,\n",
       " '[unused472]': 477,\n",
       " '##bered': 22408,\n",
       " 'dungeon': 16633,\n",
       " 'construct': 9570,\n",
       " '##》': 30166,\n",
       " 'aspiring': 22344,\n",
       " 'wolverine': 22162,\n",
       " '##ม': 29951,\n",
       " 'aston': 14327,\n",
       " 'ρ': 1171,\n",
       " 'moved': 2333,\n",
       " '##cute': 26869,\n",
       " 'intent': 7848,\n",
       " 'criteria': 9181,\n",
       " '##more': 5974,\n",
       " '##kling': 20260,\n",
       " 'concourse': 28571,\n",
       " 'several': 2195,\n",
       " 'regain': 12452,\n",
       " 'scowl': 19981,\n",
       " 'handicapped': 26920,\n",
       " 'phrases': 15672,\n",
       " '##morphic': 18078,\n",
       " 'bruise': 24851,\n",
       " 'colby': 18650,\n",
       " '1656': 28434,\n",
       " '272': 24231,\n",
       " 'occurrence': 14404,\n",
       " '##lb': 20850,\n",
       " 'amplifier': 22686,\n",
       " 'abdullah': 14093,\n",
       " 'impossible': 5263,\n",
       " 'dublin': 5772,\n",
       " 'remixed': 17574,\n",
       " 'rochelle': 25649,\n",
       " 'yellowstone': 29231,\n",
       " 'wild': 3748,\n",
       " '<BERTRAM:IDturnheadsID>': 31673,\n",
       " 'forthcoming': 16875,\n",
       " 'halo': 17201,\n",
       " 'methane': 24481,\n",
       " 'medina': 15761,\n",
       " 'estates': 8707,\n",
       " 'walks': 7365,\n",
       " 'plate': 5127,\n",
       " 'creator': 8543,\n",
       " 'deborah': 15555,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6537da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max possible length of a line containing tab separated embeddings, a rough estimate\n",
    "MAX_EMB_LINE_LENGTH = (64 + 1)*768\n",
    "\n",
    "def get_single_token_embeddings(tok_id):\n",
    "    emb_vec = embedding_weights[tok_id].detach().numpy()\n",
    "    return emb_vec\n",
    "\n",
    "def get_embedding_string(emb_vec):\n",
    "    \"\"\"\n",
    "    # Convert one embedding vector from numpy array into a tab separated string format\n",
    "    # NOTE: The float64 precision is used here!!\n",
    "    \"\"\"\n",
    "    emb_str = np.array2string(emb_vec, separator='\\t', \\\n",
    "                              max_line_width=MAX_EMB_LINE_LENGTH, \\\n",
    "                              formatter={'float_kind':lambda x: str(np.float64(x))}, \\\n",
    "                              suppress_small=False, floatmode='maxprec')\n",
    "    # Trim [ and ] characters\n",
    "    emb_str = emb_str[1:-1]\n",
    "    return emb_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f89f66",
   "metadata": {},
   "source": [
    "## Word to Embedding string mapping\n",
    "Create a map of <tok_word, embedding_str> for both pie single-tokens and the constituent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f951f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created word-embedding string mapping for 55 tokens\n"
     ]
    }
   ],
   "source": [
    "word_emb_str_mapping = {}\n",
    "\n",
    "# First process all the pie single-tokens\n",
    "for tok_word, tok_id in single_token_to_id_mapping.items():\n",
    "    emb_vec = get_single_token_embeddings(tok_id)\n",
    "    emb_str = get_embedding_string(emb_vec)\n",
    "    word_emb_str_mapping[tok_word] = emb_str\n",
    "    \n",
    "# Then process all the constituent words(Note: we have array of subtokens per each word!)\n",
    "def get_average_embedding(token_ids):\n",
    "    all_emb_vecs = []\n",
    "    for tok_id in token_ids:\n",
    "        emb_vec = get_single_token_embeddings(tok_id)\n",
    "        all_emb_vecs.append(emb_vec)\n",
    "    np_embs = np.array(all_emb_vecs)\n",
    "    avg_emb = np_embs.mean(axis=0)\n",
    "    return avg_emb\n",
    "    \n",
    "for word, tok_ids in word_to_ids.items():\n",
    "    emb_vec = get_average_embedding(tok_ids)\n",
    "    emb_str = get_embedding_string(emb_vec)\n",
    "    word_emb_str_mapping[word] = emb_str\n",
    "    \n",
    "print(f\"Created word-embedding string mapping for {len(word_emb_str_mapping)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df2a737",
   "metadata": {},
   "source": [
    "### Add sample paraphrases and synonyms\n",
    "Add the paraphrases and synonyms as well. The embeddings are obtained by averaging the embeddings of the subtokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66912f4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added additional paraphrases & synonyms of sample PIEs.\n",
      "The final word-embedding string mapping contains 86 tokens\n"
     ]
    }
   ],
   "source": [
    "COMMON_PARAPHRASES = WORDLIST_DICT['paraphrases']\n",
    "for paraphrase in COMMON_PARAPHRASES:\n",
    "    # Get the average embeddings for each paraphrase\n",
    "    tok_ids = tokenizer.encode(paraphrase, add_special_tokens=False)\n",
    "    emb_vec = get_average_embedding(tok_ids)\n",
    "    para_emb_str = get_embedding_string(emb_vec)\n",
    "\n",
    "    # Append to the mapping dictionary\n",
    "    word_emb_str_mapping[paraphrase] = para_emb_str\n",
    "    \n",
    "print(\"Added additional paraphrases & synonyms of sample PIEs.\")\n",
    "print(f\"The final word-embedding string mapping contains {len(word_emb_str_mapping)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b94fa70",
   "metadata": {},
   "source": [
    "### Add the MAGPIE words as well\n",
    "Add all the words selected from MAGPIE corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f706bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added words from MAGPIE corpus!\n",
      "The final word-embedding string mapping contains 1614 tokens\n"
     ]
    }
   ],
   "source": [
    "for mword in MAGPIE_WORD_SET:\n",
    "    # Get the average embeddings for each word\n",
    "    tok_ids = tokenizer.encode(mword, add_special_tokens=False)\n",
    "    emb_vec = get_average_embedding(tok_ids)\n",
    "    mword_emb_str = get_embedding_string(emb_vec)\n",
    "\n",
    "    # Append to the mapping dictionary\n",
    "    word_emb_str_mapping[mword] = mword_emb_str\n",
    "    \n",
    "print(\"Added words from MAGPIE corpus!\")\n",
    "print(f\"The final word-embedding string mapping contains {len(word_emb_str_mapping)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f96078",
   "metadata": {},
   "source": [
    "## Save the tokens and embedding strings into separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4118cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of words:1586\n"
     ]
    }
   ],
   "source": [
    "# Maintain a very specific order of words and be consistent across different experiments!!!\n",
    "# 1. Combine the PIEs, paraphrases, the words from WORDLIST_DICT and the MAGPIE words \n",
    "# 2. Remove duplicates!!\n",
    "# 3. and sort them!!\n",
    "\n",
    "final_word_set = set(WORDLIST_DICT['PIE_list'] + WORDLIST_DICT['paraphrases'] + WORDLIST_DICT['words'] + list(MAGPIE_WORD_SET))\n",
    "SORTED_word_list = list(sorted(final_word_set))\n",
    "\n",
    "print(f'Final number of words:{len(SORTED_word_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4506ddb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved word and embedding TSV files at ./embedding_dump/\n"
     ]
    }
   ],
   "source": [
    "outfile_prefix = exp_name + '_' + wordlist_set_NAME\n",
    "word_file_path = os.path.join(dump_dir, outfile_prefix + '_words.tsv')\n",
    "embedding_file_path = os.path.join(dump_dir, outfile_prefix + '_vectors.tsv')\n",
    "\n",
    "# For every token in the additional tokens, get the embedding vector\n",
    "# Append the token to word_file, append the tab-separated emebeddings to embeddings_file\n",
    "with open(word_file_path, 'a') as word_file:\n",
    "    with open(embedding_file_path, 'a') as embedding_file:\n",
    "        # Write to the file in the exact same order!!\n",
    "        for tok_word in SORTED_word_list:\n",
    "            output_tok_word = None\n",
    "            if tok_word.startswith(\"<BERTRAM:\"):\n",
    "                output_tok_word = ID_BERTRAM_map[tok_word]\n",
    "            else:\n",
    "                output_tok_word = tok_word\n",
    "\n",
    "            # Save tok_word\n",
    "            word_file.write(output_tok_word + '\\n')\n",
    "            \n",
    "            # Get the corresponding embedding\n",
    "            emb_str = word_emb_str_mapping[tok_word]\n",
    "            # Save emb_str\n",
    "            embedding_file.write(emb_str + '\\n')\n",
    "\n",
    "print(f'Saved word and embedding TSV files at {dump_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016170e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAB_VENV",
   "language": "python",
   "name": "lab_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
